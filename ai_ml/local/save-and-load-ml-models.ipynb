{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python : How to Save and Load ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**object serialization**\n",
    "This process / procedure of saving a ML Model is also known as object serialization - representing an object with a stream of bytes, in order to store it on disk, send it over a network or save to a database.\n",
    "\n",
    "**deserialization**\n",
    "While the restoring/reloading of ML Model procedure is known as deserialization. \n",
    "\n",
    "In this notebook, we explore 2 ways to Save and Reload ML Models in Python and scikit-learn, we will also discuss about the pros and cons of each method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be covering 2 approaches of Saving and Reloading a ML Model -\n",
    "\n",
    "1) Pickle Approach\n",
    "2) Joblib Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ML Model Creation**\n",
    "\n",
    "For the purpose of Demo , we will create a basic Logistic Regression Model on IRIS Dataset.\n",
    "Dataset used : IRIS \n",
    "Model        : Logistic Regression using Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required packages \n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.datasets import load_iris  \n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "Iris_data = load_iris()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(Iris_data.data, \n",
    "                                                    Iris_data.target, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 18)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, max_iter=20, solver='liblinear')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Model\n",
    "log_reg = LogisticRegression(C = 0.1,  \n",
    "                              max_iter = 20, \n",
    "                              fit_intercept = True, \n",
    "                              solver = 'liblinear')\n",
    "\n",
    "# Train the Model\n",
    "log_reg.fit(x_train, y_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach 1 : Pickle approach**\n",
    "\n",
    "Following lines of code, the log_reg which we created in the previous step is saved to file, and then loaded as a new object called pickle_log_reg. \n",
    "The loaded model is then used to calculate the accuracy score and predict outcomes on new unseen (test) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pickle Package\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Modle to file in the current working directory\n",
    "pkl_filename = \"save/pickle_log_reg.pkl\"  \n",
    "\n",
    "with open(pkl_filename, 'wb') as file:  \n",
    "    pickle.dump(log_reg, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, max_iter=20, solver='liblinear')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Model back from file\n",
    "with open(pkl_filename, 'rb') as file:  \n",
    "    pickle_log_reg = pickle.load(file)\n",
    "\n",
    "pickle_log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 96.67 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 2, 0, 2, 1, 2, 1, 0, 2, 0, 2, 0, 2, 0, 0, 1, 2,\n",
       "       2, 1, 2, 0, 0, 0, 2, 2])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the Reloaded Model to \n",
    "# Calculate the accuracy score and predict target values\n",
    "\n",
    "# Calculate the Score \n",
    "score = pickle_log_reg.score(x_test, y_test)  \n",
    "\n",
    "# Print the Score\n",
    "print(\"Test score: {0:.2f} %\".format(100 * score))  \n",
    "\n",
    "# Predict the Labels using the reloaded Model\n",
    "y_pred = pickle_log_reg.predict(x_test)  \n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's Reflect back on Pickle approach :**\n",
    "\n",
    "PROs of Pickle :\n",
    "\n",
    "1) save and restore our learning models is quick - we can do it in two lines of code. \n",
    "2) It is useful if you have optimized the model's parameters on the training data, so you don't need to repeat this step again. \n",
    "\n",
    "\n",
    "CONs of Pickle :\n",
    "\n",
    "1) it doesn't save the test results or any data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach 2 - Joblib** :\n",
    "\n",
    "The Joblib Module is available from Scikit Learn package and is intended to be a replacement for Pickle, for objects containing large data. \n",
    "\n",
    "This approach will save our ML Model in the pickle format only but we dont need to load additional libraries as the 'Pickling' facility is available within Scikit Learn package itself which we will use invariably for developing our ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Joblib Module from Scikit Learn\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['save/joblib_log_reg.joblib']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save RL_Model to file in the current working directory\n",
    "joblib_file = \"save/joblib_log_reg.joblib\"  \n",
    "joblib.dump(log_reg, joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, max_iter=20, solver='liblinear')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load from file\n",
    "joblib_log_reg = joblib.load(joblib_file)\n",
    "\n",
    "joblib_log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 96.67 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 2, 0, 2, 1, 2, 1, 0, 2, 0, 2, 0, 2, 0, 0, 1, 2,\n",
       "       2, 1, 2, 0, 0, 0, 2, 2])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the Reloaded Joblib Model to \n",
    "# Calculate the accuracy score and predict target values\n",
    "\n",
    "# Calculate the Score \n",
    "score2 = joblib_log_reg.score(x_test, y_test)  \n",
    "\n",
    "# Print the Score\n",
    "print(\"Test score: {0:.2f} %\".format(100 * score2))  \n",
    "\n",
    "# Predict the Labels using the reloaded Model\n",
    "y_pred2 = joblib_log_reg.predict(x_test)  \n",
    "\n",
    "y_pred2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's Reflect back on Joblib approach :**\n",
    "\n",
    "PROs of Joblib :\n",
    "\n",
    "1) the Joblib library offers a bit simpler workflow compared to Pickle. \n",
    "2) While Pickle requires a file object to be passed as an argument, Joblib works with both file objects and string filenames. \n",
    "3) In case our model contains large arrays of data, each array will be stored in a separate file, but the save and restore procedure will remain the same. \n",
    "4) Joblib also allows different compression methods, such as 'zlib', 'gzip', 'bz2', and different levels of compression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
