{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpRsp6gPO_ei"
   },
   "source": [
    "# Vertex LLM Demo: Simplify Complex Information\n",
    "\n",
    "This demo aims to distill critical points from text and informaton that is more consumable for non-experts to understand.  This could make information delivery more efficient more both the giver and receiver of information, for example a medical provider and a patient.\n",
    "\n",
    "# CUJs\n",
    "  * As a patient, I want to understand what this medical note means to me\n",
    "  * As a provider, I want to focus on critical and objective medical diagnoses and prognoses, and expedite delivery of information to patients.\n",
    "  * As a product manager, I want to understand the implications of a new technology to my product or future products.\n",
    "  * and many, many more...\n",
    "\n",
    "# What the code does\n",
    "\n",
    "  * The code takes a text as input, such as a medical chart note or complex technical explanation.\n",
    "  * It then pulls that text into a prompt, instructing the LLM to generate a  summary of the text for an individual at a more appropriate knowledge level (e.g. non-expert, patient, student).\n",
    "  * The model responds with a summary, and sometimes deeper explanations if certain terms within the summary still require expounding upon.\n",
    "\n",
    "# Instructions\n",
    "\n",
    "To run the demo, simply run all the cells in order. The hidden cells can remain hidden and you can run the entire section at once. Note that the workspace setup will trigger a runtime restart; that is working as intended to ensure the right version of the Cloud SDK is installed.\n",
    "\n",
    "\n",
    "# Limitations and ideas for extension\n",
    "\n",
    "  * Could possibly be used in a more real-time scenario as part of a chatbot deployed by medical providers / teachers / product teams / etc..\n",
    "  * The body of text currently needs to fit within the LLM's context window. We can naively solve that problem by chunking up the original body of text and generating summaries of smaller chunks.\n",
    "  * Some of the input could be sensitive and directly impactful, e.g. in the case of medical information, so the summary would need to be validated prior to a patient, student, individual seeing to ensure minimal or no misinformation.\n",
    "\n",
    "# Sample output\n",
    "\n",
    "**Original text**\n",
    "\n",
    "*72 year old man with h/o CHF following MI, chronic renal insufficiency and venous stasis admitted with worsening edema and DOE. His symptoms are most consistent with incrasing CHF-biventricular-which would account for both his pulmonary congestion as well as his peripheral edema. His renal disease is a less likely explanation for his extensive edema as his BUN/Cr have remained stable throughout. However, his low albumin which could contribute to his edema may be due to renal losses. So if his edema is due to CHF, why has it become gradually and now acutely worse? Possibilities include: 1) worsening LV function, 2) another MI, 3) worsening valvular disease, 4) poor compliance with medications or 5) excess salt and water intake. His ECHO today shows no change in his EF, but there is marked wall motion abnormalities with akinesis. There is no evidence in his history, EKG, or enzymes for current ischemia/infarct. He does have MR and TR and his valvular disease may in part account for his worsening symptoms though his estimated PA pressure is unchanged and his LA is not dilated. The most likely precipitant of his failure is a combination of poor compliance with medication and fluid overload from excessive intake. We will continue to investigate the possibility of a structural precipitant for his deterioration and treat his current symptoms.*\n",
    "\n",
    "**Response - non-expert summary (text-bison-001 model)**\n",
    "\n",
    "*72 year old man with heart failure due to previous heart attack, kidney disease and poor circulation is admitted to hospital with worsening symptoms. Doctors are trying to figure out what caused his condition to get worse. They think it could be because his heart is not working as well as it used to, or because he has another heart problem, or because he is not taking his medication properly, or because he is drinking too much water and eating too much salt. They will do more tests to find out the cause and treat his symptoms.*\n",
    "\n",
    "**Expanded Response - explanation of non-expert summary (text-bison-001 model)**\n",
    "\n",
    "*72 year old man with heart failure due to previous heart attack, kidney disease and poor circulation is admitted to hospital with worsening symptoms. Doctors are trying to figure out what caused his condition to get worse. They think it could be because his heart is not working as well as it used to, or because he has another heart problem, or because he is not taking his medication properly, or because he is drinking too much water and eating too much salt. They will do more tests to find out the cause and treat his symptoms.*\n",
    "\n",
    "*A 72-year-old man with heart failure due to a previous heart attack, kidney disease, and poor circulation was admitted to the hospital with worsening symptoms. The doctors are trying to figure out what caused his condition to get worse. They think it could be because his heart is not working as well as it used to, or because he has another heart problem, or because he is not taking his medication properly, or because he is drinking too much water and eating too much salt. They will do more tests to find out the cause and treat his symptoms.*\n",
    "\n",
    "*Heart failure is a condition in which the heart cannot pump enough blood to meet the body's needs. This can lead to symptoms such as shortness of breath, fatigue, and swelling in the feet, ankles, and legs. Heart failure can be caused by a number of factors, including heart attack, high blood pressure, and diabetes.*\n",
    "\n",
    "*Kidney disease is a condition in which the kidneys cannot function properly. This can lead to symptoms such as swelling, fatigue, and urination problems. Kidney disease can be caused by a number of factors, including high blood pressure, diabetes, and smoking.*\n",
    "\n",
    "*Poor circulation is a condition in which the blood does not flow properly through the body. This can lead to symptoms such as coldness, numbness, and pain in the feet, ankles, and legs. Poor circulation can be caused by a number of factors, including high blood pressure, diabetes, and smoking.*\n",
    "\n",
    "*The doctors are trying to figure out what caused the man's condition to get worse. They think it could be because his heart is not working as well as it used to, or because he has another heart problem, or because he is not taking his medication properly, or because he is drinking too much water and eating too much salt. They will do more tests to find out the cause and treat his symptoms.*\n",
    "\n",
    "*The man's treatment will depend on the cause of his condition. If his heart is not working as well as it used to, he may need surgery to repair or replace his heart. If he has another heart problem, he may need medication to treat it. If he is not taking his medication properly, he will need to be started on a new medication regimen. If he is drinking too much water and eating too much salt, he will need to be put on a diet that restricts his fluid and salt intake.*\n",
    "\n",
    "*The man's prognosis will depend on the cause of his condition and how well he responds to treatment. If his heart is not working as well as it used to, he may have a poor prognosis. If he has another heart problem, he may also have a poor prognosis. However, if he is taking his medication properly and is not drinking too much water and eating too much salt, he may have a good prognosis.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ZUJB93GQmAI"
   },
   "source": [
    "## Workspace Setup ##\n",
    "\n",
    "---\n",
    "\n",
    "Run the hidden cells to set up the workspace. Note that it will automatically restart the runtime to install the Google Cloud SDK.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MQJDgFB0jEH0"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m auth \u001b[38;5;28;01mas\u001b[39;00m google_auth\n\u001b[1;32m      2\u001b[0m google_auth\u001b[38;5;241m.\u001b[39mauthenticate_user()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import auth as google_auth\n",
    "google_auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "executionInfo": {
     "elapsed": 9657,
     "status": "ok",
     "timestamp": 1682428966540,
     "user": {
      "displayName": "Mike Goodman",
      "userId": "06815737826177427562"
     },
     "user_tz": 240
    },
    "id": "Dr7wQN67i580",
    "outputId": "7160ad7a-ef77-4504-fb95-adb7c9020e5a"
   },
   "outputs": [],
   "source": [
    "# !gsutil cp gs://agravat-octo-aif-sandbox-central/llm_demo/google_cloud_aiplatform-1.23.0.llm.alpha.23.03.28-py2.py3-none-any.whl .\n",
    "# !pip install google_cloud_aiplatform-1.23.0.llm.alpha.23.03.28-py2.py3-none-any.whl \"shapely<2.0.0\"\n",
    "\n",
    "!pip3 uninstall -y google-cloud-aiplatform\n",
    "!pip3 install google-cloud-aiplatform\n",
    "\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G1op-7KDlG5R"
   },
   "source": [
    "## LLM Setup ##\n",
    "\n",
    "---\n",
    "\n",
    "This section sets up an easy interface for interaction with Vertex LLM.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lWGrekhmjgIF"
   },
   "outputs": [],
   "source": [
    "## Pulled from OCTO examples.  Simplifies the calls to the GenAI models.\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform_v1.types.prediction_service import PredictResponse\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "\n",
    "class VertexLLM:\n",
    "\n",
    "    MODEL_TEXT_BISON_001 = \"text-bison-001\"\n",
    "    MODEL_TEXT_BISON_ALPHA = \"text-bison-alpha\"\n",
    "\n",
    "    def __init__(self, endpoint=\"us-central1-aiplatform.googleapis.com\", project=\"cloud-large-language-models\", location=\"us-central1\"):\n",
    "        self.client = aiplatform.gapic.PredictionServiceClient(client_options={\"api_endpoint\": endpoint})\n",
    "        self.project = project\n",
    "        self.location = location\n",
    "\n",
    "    def predict(self, content, model=MODEL_TEXT_BISON_001, temp=0.2, max_tokens=1024, top_p=0.95, top_k=40, **kwargs):\n",
    "        endpoint = self.client.endpoint_path(project=self.project, location=self.location, endpoint=model)\n",
    "        instance = json_format.ParseDict({\"content\": content}, Value())\n",
    "        params = {\n",
    "                \"temperature\": temp,\n",
    "                \"maxDecodeSteps\": max_tokens,\n",
    "                \"topP\": top_p,\n",
    "                \"topK\": top_k,\n",
    "        }\n",
    "        response = self.client.predict(endpoint=endpoint, instances=[instance], parameters=params, **kwargs)\n",
    "        response_dict = PredictResponse.to_dict(response)\n",
    "        return response_dict['predictions'][0]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "f3STS1XYSBdD"
   },
   "outputs": [],
   "source": [
    "vertex_llm = VertexLLM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kQBpFXVw4E-"
   },
   "source": [
    "## Upload Sample Body of Text##\n",
    "\n",
    "---\n",
    "\n",
    "This section provides some example medical chart notes that a patient may see when provided by a provider.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3e2FIHQ6w4uh"
   },
   "outputs": [],
   "source": [
    "# pulled from sources such as: https://www.mtsamples.com/site/pages/browse.asp?Type=87-Office%20Notes\n",
    "\n",
    "text_samples_med = [\n",
    "\"\"\"\n",
    "72 year old man with h/o CHF following MI, chronic renal insufficiency and venous stasis admitted with worsening edema and DOE.\n",
    "His symptoms are most consistent with incrasing CHF-biventricular-which would account for both his pulmonary congestion as well as his peripheral edema.\n",
    "His renal disease is a less likely explanation for his extensive edema as his BUN/Cr have remained stable throughout.\n",
    "However, his low albumin which could contribute to his edema may be due to renal losses.\n",
    "So if his edema is due to CHF, why has it become gradually and now acutely worse? Possibilities include:\n",
    "1) worsening LV function, 2) another MI, 3) worsening valvular disease, 4) poor compliance with medications or\n",
    "5) excess salt and water intake. His ECHO today shows no change in his EF, but there is marked wall motion abnormalities with akinesis.\n",
    "There is no evidence in his history, EKG, or enzymes for current ischemia/infarct.\n",
    "He does have MR and TR and his valvular disease may in part account for his worsening symptoms though his estimated PA pressure is unchanged and his LA is not dilated.\n",
    "The most likely precipitant of his failure is a combination of poor compliance with medication and fluid overload from excessive intake.\n",
    "We will continue to investigate the possibility of a structural precipitant for his deterioration and treat his current symptoms.\n",
    "\"\"\"\n",
    ",\"\"\"\n",
    "This 66-year-old white male was seen in my office on Month DD, YYYY. Patient was recently discharged from Doctors Hospital at Parkway after he was treated for pneumonia.\n",
    "Patient continues to have severe orthopnea, paroxysmal nocturnal dyspnea, cough with greenish expectoration.\n",
    "His exercise tolerance is about two to three yards for shortness of breath.\n",
    "The patient stopped taking Coumadin for reasons not very clear to him. He was documented to have recent atrial fibrillation.\n",
    "Patient has longstanding history of ischemic heart disease, end-stage LV systolic dysfunction, and is status post ICD implantation.\n",
    "Fasting blood sugar this morning is 130.\n",
    "\"\"\"\n",
    ",\"\"\"\n",
    "This 32-year-old with family history of premature coronary artery disease came in for evaluation of recurrent chest pain, O2 saturation at 94% with both atypical and typical features of ischemia.\n",
    "The patient ruled out for myocardial infarction with serial troponins.\n",
    "Nuclear stress test has been done, results of which are pending.\n",
    "The patient is stable to be discharged pending the results of nuclear stress test and cardiologist's recommendations.\n",
    "He will follow up with cardiologist, Dr. X, in two weeks and with his primary physician in two to four weeks.\n",
    "Discharge medications will depend on results of nuclear stress test.\n",
    "\"\"\"\n",
    ",\"\"\"\n",
    "The patient returns to our office today because of continued problems with her headaches.\n",
    "She was started on Zonegran on her last visit and she states that initially she titrated upto 100 mg q.h.s.\n",
    "Initially felt that the Zonegran helped, but then the pain in her head returned.\n",
    "It is an area of tenderness and sensitivity in her left parietal area.\n",
    "It is a very localized pain.\n",
    "She takes Motrin 400 mg b.i.d., which helped.\n",
    "She also had EMG/nerve conduction studies since she was last seen in our office that showed severe left ulnar neuropathy, moderate right ulnar neuropathy, bilateral mild-to-moderate carpal tunnel and diabetic neuropathy.\n",
    "She was referred to Dr. XYZ and will be seeing him on August 8, 2006.\n",
    "She was also never referred to the endocrine clinic to deal with her poor diabetes control.\n",
    "Her last hemoglobin A1c was 10.\n",
    "\"\"\"\n",
    "]\n",
    "text_samples_tech_math = [\n",
    "\"\"\"\n",
    "In probability theory and statistics, Bayes' theorem (alternatively Bayes' law or Bayes' rule), named after Thomas Bayes, describes the probability of an event, based on prior knowledge of conditions that might be related to the event.For example, if the risk of developing health problems is known to increase with age, Bayes' theorem allows the risk to an individual of a known age to be assessed more accurately by conditioning it relative to their age, rather than simply assuming that the individual is typical of the population as a whole.\n",
    "One of the many applications of Bayes' theorem is Bayesian inference, a particular approach to statistical inference. When applied, the probabilities involved in the theorem may have different probability interpretations. With Bayesian probability interpretation, the theorem expresses how a degree of belief, expressed as a probability, should rationally change to account for the availability of related evidence. Bayesian inference is fundamental to Bayesian statistics, being considered by one authority as; \"to the theory of probability what Pythagoras's theorem is to geometry.\n",
    "\"\"\"\n",
    ",\"\"\"\n",
    "Compound interest is the addition of interest to the principal sum of a loan or deposit, or in other words, interest on principal plus interest. It is the result of reinvesting interest, or adding it to the loaned capital rather than paying it out, or requiring payment from borrower, so that interest in the next period is then earned on the principal sum plus previously accumulated interest. Compound interest is standard in finance and economics.\n",
    "Compound interest is contrasted with simple interest, where previously accumulated interest is not added to the principal amount of the current period, so there is no compounding. The simple annual interest rate is the interest amount per period, multiplied by the number of periods per year. The simple annual interest rate is also known as the nominal interest rate (not to be confused with the interest rate not adjusted for inflation, which goes by the same name).\n",
    "\"\"\"\n",
    ",\"\"\"\n",
    "An application programming interface (API) is a way for two or more computer programs to communicate with each other. It is a type of software interface, offering a service to other pieces of software.[1] A document or standard that describes how to build or use such a connection or interface is called an API specification. A computer system that meets this standard is said to implement or expose an API. The term API may refer either to the specification or to the implementation.\n",
    "In contrast to a user interface, which connects a computer to a person, an application programming interface connects computers or pieces of software to each other. It is not intended to be used directly by a person (the end user) other than a computer programmer who is incorporating it into the software. An API is often made up of different parts which act as tools or services that are available to the programmer. A program or a programmer that uses one of these parts is said to call that portion of the API. The calls that make up the API are also known as subroutines, methods, requests, or endpoints. An API specification defines these calls, meaning that it explains how to use or implement them.\n",
    "One purpose of APIs is to hide the internal details of how a system works, exposing only those parts a programmer will find useful and keeping them consistent even if the internal details later change. An API may be custom-built for a particular pair of systems, or it may be a shared standard allowing interoperability among many systems.\n",
    "There are APIs for programming languages, software libraries, computer operating systems, and computer hardware. APIs originated in the 1940s, though the term did not emerge until the 1960s and 1970s. Contemporary usage of the term API often refers to web APIs,[2] which allow communication between computers that are joined by the internet. Recent developments in APIs have led to the rise in popularity of microservices, which are loosely coupled services accessed through public APIs.\n",
    "\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1682429337382,
     "user": {
      "displayName": "Mike Goodman",
      "userId": "06815737826177427562"
     },
     "user_tz": 240
    },
    "id": "TAVeNDFXYS4Q",
    "outputId": "dc53387b-8b86-4f72-96ce-9ce8fd9d44a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "72 year old man with h/o CHF following MI, chronic renal insufficiency and venous stasis admitted with worsening edema and DOE.\n",
      "His symptoms are most consistent with incrasing CHF-biventricular-which would account for both his pulmonary congestion as well as his peripheral edema.\n",
      "His renal disease is a less likely explanation for his extensive edema as his BUN/Cr have remained stable throughout.\n",
      "However, his low albumin which could contribute to his edema may be due to renal losses.\n",
      "So if his edema is due to CHF, why has it become gradually and now acutely worse? Possibilities include:\n",
      "1) worsening LV function, 2) another MI, 3) worsening valvular disease, 4) poor compliance with medications or\n",
      "5) excess salt and water intake. His ECHO today shows no change in his EF, but there is marked wall motion abnormalities with akinesis.\n",
      "There is no evidence in his history, EKG, or enzymes for current ischemia/infarct.\n",
      "He does have MR and TR and his valvular disease may in part account for his worsening symptoms though his estimated PA pressure is unchanged and his LA is not dilated.\n",
      "The most likely precipitant of his failure is a combination of poor compliance with medication and fluid overload from excessive intake.\n",
      "We will continue to investigate the possibility of a structural precipitant for his deterioration and treat his current symptoms.\n",
      "\n",
      "\n",
      "In probability theory and statistics, Bayes' theorem (alternatively Bayes' law or Bayes' rule), named after Thomas Bayes, describes the probability of an event, based on prior knowledge of conditions that might be related to the event.For example, if the risk of developing health problems is known to increase with age, Bayes' theorem allows the risk to an individual of a known age to be assessed more accurately by conditioning it relative to their age, rather than simply assuming that the individual is typical of the population as a whole.\n",
      "One of the many applications of Bayes' theorem is Bayesian inference, a particular approach to statistical inference. When applied, the probabilities involved in the theorem may have different probability interpretations. With Bayesian probability interpretation, the theorem expresses how a degree of belief, expressed as a probability, should rationally change to account for the availability of related evidence. Bayesian inference is fundamental to Bayesian statistics, being considered by one authority as; \"to the theory of probability what Pythagoras's theorem is to geometry.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text_samples_med[0])\n",
    "print(text_samples_tech_math[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OxnLl0erRwPo"
   },
   "source": [
    "## Generate Summaries ##\n",
    "\n",
    "---\n",
    "\n",
    "Here we create a basic summary generation prompt and print the results.\n",
    "\n",
    "Results are OK.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 984
    },
    "executionInfo": {
     "elapsed": 12165,
     "status": "ok",
     "timestamp": 1682429368990,
     "user": {
      "displayName": "Mike Goodman",
      "userId": "06815737826177427562"
     },
     "user_tz": 240
    },
    "id": "WTVIi0TxrrQG",
    "outputId": "ea62a6f4-238f-4fa8-aa77-7f7faa33194e"
   },
   "outputs": [
    {
     "ename": "PermissionDenied",
     "evalue": "403 Permission 'aiplatform.endpoints.predict' denied on resource '//aiplatform.googleapis.com/projects/cloud-large-language-models/locations/us-central1/endpoints/text-bison-001' (or it may not exist). [reason: \"IAM_PERMISSION_DENIED\"\ndomain: \"aiplatform.googleapis.com\"\nmetadata {\n  key: \"resource\"\n  value: \"projects/cloud-large-language-models/locations/us-central1/endpoints/text-bison-001\"\n}\nmetadata {\n  key: \"permission\"\n  value: \"aiplatform.endpoints.predict\"\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/api_core/grpc_helpers.py:72\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/grpc/_channel.py:946\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    944\u001b[0m state, call, \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(request, timeout, metadata, credentials,\n\u001b[1;32m    945\u001b[0m                               wait_for_ready, compression)\n\u001b[0;32m--> 946\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/grpc/_channel.py:849\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 849\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.PERMISSION_DENIED\n\tdetails = \"Permission 'aiplatform.endpoints.predict' denied on resource '//aiplatform.googleapis.com/projects/cloud-large-language-models/locations/us-central1/endpoints/text-bison-001' (or it may not exist).\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv6:%5B2607:f8b0:4002:c10::5f%5D:443 {created_time:\"2023-06-15T11:51:13.766005-04:00\", grpc_status:7, grpc_message:\"Permission \\'aiplatform.endpoints.predict\\' denied on resource \\'//aiplatform.googleapis.com/projects/cloud-large-language-models/locations/us-central1/endpoints/text-bison-001\\' (or it may not exist).\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPermissionDenied\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m\n\u001b[1;32m      5\u001b[0m generation_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124mGenerate a summary of the following text.\u001b[39m\n\u001b[1;32m      7\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124mSummary:\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(text)\n\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m VertexLLM\u001b[38;5;241m.\u001b[39mMODEL_TEXT_BISON_001\n\u001b[0;32m---> 15\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mvertex_llm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeneration_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m display(Markdown(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m## Original text\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     18\u001b[0m display(Markdown(text))\n",
      "Cell \u001b[0;32mIn[2], line 27\u001b[0m, in \u001b[0;36mVertexLLM.predict\u001b[0;34m(self, content, model, temp, max_tokens, top_p, top_k, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m instance \u001b[38;5;241m=\u001b[39m json_format\u001b[38;5;241m.\u001b[39mParseDict({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: content}, Value())\n\u001b[1;32m     21\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temp,\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxDecodeSteps\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopP\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopK\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_k,\n\u001b[1;32m     26\u001b[0m }\n\u001b[0;32m---> 27\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstances\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m response_dict \u001b[38;5;241m=\u001b[39m PredictResponse\u001b[38;5;241m.\u001b[39mto_dict(response)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py:602\u001b[0m, in \u001b[0;36mPredictionServiceClient.predict\u001b[0;34m(self, request, endpoint, instances, parameters, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    597\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(metadata) \u001b[38;5;241m+\u001b[39m (\n\u001b[1;32m    598\u001b[0m     gapic_v1\u001b[38;5;241m.\u001b[39mrouting_header\u001b[38;5;241m.\u001b[39mto_grpc_metadata(((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mendpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mendpoint),)),\n\u001b[1;32m    599\u001b[0m )\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/api_core/gapic_v1/method.py:113\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     metadata\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata)\n\u001b[1;32m    111\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metadata\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/api_core/grpc_helpers.py:74\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mPermissionDenied\u001b[0m: 403 Permission 'aiplatform.endpoints.predict' denied on resource '//aiplatform.googleapis.com/projects/cloud-large-language-models/locations/us-central1/endpoints/text-bison-001' (or it may not exist). [reason: \"IAM_PERMISSION_DENIED\"\ndomain: \"aiplatform.googleapis.com\"\nmetadata {\n  key: \"resource\"\n  value: \"projects/cloud-large-language-models/locations/us-central1/endpoints/text-bison-001\"\n}\nmetadata {\n  key: \"permission\"\n  value: \"aiplatform.endpoints.predict\"\n}\n]"
     ]
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "for text in text_samples_med:\n",
    "\n",
    "  generation_prompt = \"\"\"\n",
    "  Generate a summary of the following text.\n",
    "\n",
    "  Text:\n",
    "  {}\n",
    "\n",
    "  Summary:\n",
    "  \"\"\".format(text)\n",
    "\n",
    "  model = VertexLLM.MODEL_TEXT_BISON_001\n",
    "  response = vertex_llm.predict(generation_prompt, model=model)\n",
    "\n",
    "  display(Markdown(\"## Original text\"))\n",
    "  display(Markdown(text))\n",
    "  display(Markdown(\"### Response ({} model)\".format(model)))\n",
    "  display(Markdown(response))\n",
    "  display(Markdown(\"-------------------------------------\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 11910,
     "status": "ok",
     "timestamp": 1682429495201,
     "user": {
      "displayName": "Mike Goodman",
      "userId": "06815737826177427562"
     },
     "user_tz": 240
    },
    "id": "E8cvJt-lnF8l",
    "outputId": "15ba7963-6658-4f4f-ddc2-fc968c1e359b"
   },
   "outputs": [
    {
     "ename": "PermissionDenied",
     "evalue": "403 Permission 'aiplatform.endpoints.predict' denied on resource '//aiplatform.googleapis.com/projects/cloud-large-language-models/locations/us-central1/endpoints/text-bison-001' (or it may not exist). [reason: \"IAM_PERMISSION_DENIED\"\ndomain: \"aiplatform.googleapis.com\"\nmetadata {\n  key: \"resource\"\n  value: \"projects/cloud-large-language-models/locations/us-central1/endpoints/text-bison-001\"\n}\nmetadata {\n  key: \"permission\"\n  value: \"aiplatform.endpoints.predict\"\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/api_core/grpc_helpers.py:72\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/grpc/_channel.py:946\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    944\u001b[0m state, call, \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(request, timeout, metadata, credentials,\n\u001b[1;32m    945\u001b[0m                               wait_for_ready, compression)\n\u001b[0;32m--> 946\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/grpc/_channel.py:849\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 849\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.PERMISSION_DENIED\n\tdetails = \"Permission 'aiplatform.endpoints.predict' denied on resource '//aiplatform.googleapis.com/projects/cloud-large-language-models/locations/us-central1/endpoints/text-bison-001' (or it may not exist).\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv6:%5B2607:f8b0:4002:c10::5f%5D:443 {created_time:\"2023-06-15T11:51:14.46182-04:00\", grpc_status:7, grpc_message:\"Permission \\'aiplatform.endpoints.predict\\' denied on resource \\'//aiplatform.googleapis.com/projects/cloud-large-language-models/locations/us-central1/endpoints/text-bison-001\\' (or it may not exist).\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPermissionDenied\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m\n\u001b[1;32m      5\u001b[0m generation_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124mGenerate a summary of the following text.\u001b[39m\n\u001b[1;32m      7\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124mSummary:\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(text)\n\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m VertexLLM\u001b[38;5;241m.\u001b[39mMODEL_TEXT_BISON_001\n\u001b[0;32m---> 15\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mvertex_llm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeneration_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m display(Markdown(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m## Original text\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     18\u001b[0m display(Markdown(text))\n",
      "Cell \u001b[0;32mIn[2], line 27\u001b[0m, in \u001b[0;36mVertexLLM.predict\u001b[0;34m(self, content, model, temp, max_tokens, top_p, top_k, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m instance \u001b[38;5;241m=\u001b[39m json_format\u001b[38;5;241m.\u001b[39mParseDict({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: content}, Value())\n\u001b[1;32m     21\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temp,\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxDecodeSteps\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopP\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopK\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_k,\n\u001b[1;32m     26\u001b[0m }\n\u001b[0;32m---> 27\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstances\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m response_dict \u001b[38;5;241m=\u001b[39m PredictResponse\u001b[38;5;241m.\u001b[39mto_dict(response)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py:602\u001b[0m, in \u001b[0;36mPredictionServiceClient.predict\u001b[0;34m(self, request, endpoint, instances, parameters, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    597\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(metadata) \u001b[38;5;241m+\u001b[39m (\n\u001b[1;32m    598\u001b[0m     gapic_v1\u001b[38;5;241m.\u001b[39mrouting_header\u001b[38;5;241m.\u001b[39mto_grpc_metadata(((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mendpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mendpoint),)),\n\u001b[1;32m    599\u001b[0m )\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/api_core/gapic_v1/method.py:113\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     metadata\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata)\n\u001b[1;32m    111\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metadata\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/google/api_core/grpc_helpers.py:74\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mPermissionDenied\u001b[0m: 403 Permission 'aiplatform.endpoints.predict' denied on resource '//aiplatform.googleapis.com/projects/cloud-large-language-models/locations/us-central1/endpoints/text-bison-001' (or it may not exist). [reason: \"IAM_PERMISSION_DENIED\"\ndomain: \"aiplatform.googleapis.com\"\nmetadata {\n  key: \"resource\"\n  value: \"projects/cloud-large-language-models/locations/us-central1/endpoints/text-bison-001\"\n}\nmetadata {\n  key: \"permission\"\n  value: \"aiplatform.endpoints.predict\"\n}\n]"
     ]
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "for text in text_samples_tech_math:\n",
    "\n",
    "  generation_prompt = \"\"\"\n",
    "  Generate a summary of the following text.\n",
    "\n",
    "  Text:\n",
    "  {}\n",
    "\n",
    "  Summary:\n",
    "  \"\"\".format(text)\n",
    "\n",
    "  model = VertexLLM.MODEL_TEXT_BISON_001\n",
    "  response = vertex_llm.predict(generation_prompt, model=model)\n",
    "\n",
    "  display(Markdown(\"## Original text\"))\n",
    "  display(Markdown(text))\n",
    "  display(Markdown(\"### Response ({} model)\".format(model)))\n",
    "  display(Markdown(response))\n",
    "  display(Markdown(\"-------------------------------------\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbKd3jJfnOO2"
   },
   "source": [
    "\n",
    "## Generate Non-Expert Summaries ##\n",
    "\n",
    "---\n",
    "\n",
    "Here we create a summary generation prompt that aims to simplify the content for non-experts and print the results.\n",
    "\n",
    "Results are better than the basic prompt.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 159,
     "status": "ok",
     "timestamp": 1682430977458,
     "user": {
      "displayName": "Mike Goodman",
      "userId": "06815737826177427562"
     },
     "user_tz": 240
    },
    "id": "7dmr0-a8sz4p",
    "outputId": "9ed4fbce-6ab4-44a2-bcf6-8b85b324e2fa"
   },
   "outputs": [],
   "source": [
    "summaries = []\n",
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 14570,
     "status": "ok",
     "timestamp": 1682430998525,
     "user": {
      "displayName": "Mike Goodman",
      "userId": "06815737826177427562"
     },
     "user_tz": 240
    },
    "id": "F7CSbbopcvlA",
    "outputId": "71e53f13-ef62-480d-9dc2-e13cb02d8ee4"
   },
   "outputs": [],
   "source": [
    "for text in text_samples_med:\n",
    "\n",
    "  generation_prompt = \"\"\"\n",
    "  Generate a summary that a non-expert would understand of the following text.\n",
    "\n",
    "  Text:\n",
    "  {}\n",
    "\n",
    "  Summary:\n",
    "  \"\"\".format(text)\n",
    "\n",
    "  model = VertexLLM.MODEL_TEXT_BISON_001\n",
    "  response = vertex_llm.predict(generation_prompt, model=model)\n",
    "  summaries.append(response)\n",
    "\n",
    "  display(Markdown(\"## Original text\"))\n",
    "  display(Markdown(text))\n",
    "  display(Markdown(\"### Response ({} model)\".format(model)))\n",
    "  display(Markdown(response))\n",
    "  display(Markdown(\"-------------------------------------\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 10817,
     "status": "ok",
     "timestamp": 1682431009340,
     "user": {
      "displayName": "Mike Goodman",
      "userId": "06815737826177427562"
     },
     "user_tz": 240
    },
    "id": "xYa1rFZ-nm0U",
    "outputId": "c7468c2d-c116-40dc-86ac-451f1747a9ac"
   },
   "outputs": [],
   "source": [
    "for text in text_samples_tech_math:\n",
    "\n",
    "  generation_prompt = \"\"\"\n",
    "  Generate a summary that a non-expert would understand of the following text.\n",
    "\n",
    "  Text:\n",
    "  {}\n",
    "\n",
    "  Summary:\n",
    "  \"\"\".format(text)\n",
    "\n",
    "  model = VertexLLM.MODEL_TEXT_BISON_001\n",
    "  response = vertex_llm.predict(generation_prompt, model=model)\n",
    "  summaries.append(response)\n",
    "\n",
    "  display(Markdown(\"## Original text\"))\n",
    "  display(Markdown(text))\n",
    "  display(Markdown(\"### Response ({} model)\".format(model)))\n",
    "  display(Markdown(response))\n",
    "  display(Markdown(\"-------------------------------------\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hs9inCtkpZ6i"
   },
   "source": [
    "\n",
    "## Generate Explanations Based on Simplified Summaries ##\n",
    "\n",
    "---\n",
    "\n",
    "Here we create an explanation generation prompt that aims to expand upon the summaries for non-experts and print the results.\n",
    "\n",
    "Results are ___.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1682431009834,
     "user": {
      "displayName": "Mike Goodman",
      "userId": "06815737826177427562"
     },
     "user_tz": 240
    },
    "id": "e6BsjnswqDXS",
    "outputId": "8f749763-d169-40ec-86dd-e2c5b9a0f2ae"
   },
   "outputs": [],
   "source": [
    "len(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 60293,
     "status": "ok",
     "timestamp": 1682431184707,
     "user": {
      "displayName": "Mike Goodman",
      "userId": "06815737826177427562"
     },
     "user_tz": 240
    },
    "id": "XdFU4IsLprq-",
    "outputId": "5f95eae5-01a6-4328-ef16-b3850cf49809"
   },
   "outputs": [],
   "source": [
    "for summary in summaries:\n",
    "\n",
    "  generation_prompt = \"\"\"\n",
    "  Generate a more detailed explanation that a non-expert would understand of the following text.\n",
    "\n",
    "  Previous Summary:\n",
    "  {}\n",
    "\n",
    "  Explanation:\n",
    "  \"\"\".format(summary)\n",
    "\n",
    "  model = VertexLLM.MODEL_TEXT_BISON_001\n",
    "  response = vertex_llm.predict(generation_prompt, model=model)\n",
    "\n",
    "  display(Markdown(\"## Original text\"))\n",
    "  display(Markdown(summary))\n",
    "  display(Markdown(\"### Response ({} model)\".format(model)))\n",
    "  display(Markdown(response))\n",
    "  display(Markdown(\"-------------------------------------\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_yRxrJC6n6zu"
   },
   "source": [
    "\n",
    "## Generate Even Simpler Summaries ##\n",
    "\n",
    "---\n",
    "\n",
    "Here we create a summary generation prompt that aims to simplify the content to even a lower level and use bullets to format and print the results.\n",
    "\n",
    "Results are generally similar to the previous attempt, and don't always include bullet points in the response.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 13723,
     "status": "ok",
     "timestamp": 1682429835252,
     "user": {
      "displayName": "Mike Goodman",
      "userId": "06815737826177427562"
     },
     "user_tz": 240
    },
    "id": "mq7vHkDtUSl8",
    "outputId": "18301ea4-7f0d-48b2-ddb4-317e7ec6217a"
   },
   "outputs": [],
   "source": [
    "for text in text_samples_med:\n",
    "\n",
    "  generation_prompt = \"\"\"\n",
    "  Generate a 3-5 bullet-point summary that a 6th grader would understand of the following text.\n",
    "\n",
    "  Text:\n",
    "  {}\n",
    "\n",
    "  Summary:\n",
    "  \"\"\".format(text)\n",
    "\n",
    "  model = VertexLLM.MODEL_TEXT_BISON_001\n",
    "  response = vertex_llm.predict(generation_prompt, model=model)\n",
    "\n",
    "  display(Markdown(\"## Original text\"))\n",
    "  display(Markdown(text))\n",
    "  display(Markdown(\"### Response ({} model)\".format(model)))\n",
    "  display(Markdown(response))\n",
    "  display(Markdown(\"-------------------------------------\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 10739,
     "status": "ok",
     "timestamp": 1682429858156,
     "user": {
      "displayName": "Mike Goodman",
      "userId": "06815737826177427562"
     },
     "user_tz": 240
    },
    "id": "F6G9CHZhcrTK",
    "outputId": "70a0b726-d204-44a4-8e3b-c5a118fb4aad"
   },
   "outputs": [],
   "source": [
    "for text in text_samples_tech_math:\n",
    "\n",
    "  generation_prompt = \"\"\"\n",
    "  Generate a 3-5 bullet-point summary that a 6th grader would understand of the following text.\n",
    "\n",
    "  Text:\n",
    "  {}\n",
    "\n",
    "  Summary:\n",
    "  \"\"\".format(text)\n",
    "\n",
    "  model = VertexLLM.MODEL_TEXT_BISON_001\n",
    "  response = vertex_llm.predict(generation_prompt, model=model)\n",
    "\n",
    "  display(Markdown(\"## Original text\"))\n",
    "  display(Markdown(text))\n",
    "  display(Markdown(\"### Response ({} model)\".format(model)))\n",
    "  display(Markdown(response))\n",
    "  display(Markdown(\"-------------------------------------\"))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "8ZUJB93GQmAI"
   ],
   "provenance": [
    {
     "file_id": "1y6-VLcwOwTKL_P7HFS9U09TqFa9YxY13",
     "timestamp": 1681738411992
    },
    {
     "file_id": "1AN-yYXFMp4-ClAzkxYCM2pRW14wox99i",
     "timestamp": 1680118336983
    },
    {
     "file_id": "1TklcZV5maqYmE10PUBujqYUoqWCRAHz2",
     "timestamp": 1680114454708
    },
    {
     "file_id": "131DABjKtvCidoc9iw48i633j-uelY1if",
     "timestamp": 1680113609815
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
