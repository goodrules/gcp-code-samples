{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sxq-V_jV4gEk",
    "tags": []
   },
   "source": [
    "# Using the Vertex AI PaLM API to Generate and Ideate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sHoUOuxf5GOR",
    "tags": []
   },
   "source": [
    "# Core code\n",
    "Let's define some variables that will be used throughout this notebook.\n",
    "\n",
    "These are the GCP Project ID `project_id`, the Model name `model_name` which is any name you prefer, and finally the Dataset name `dataset_name`.\n",
    "The dataset needs to exist in the same Project as `project_id` and you'll need appropriate access to create and delete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fU3_zsLsZ89c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 11:29:15.876367: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from typing import Union\n",
    "import sys\n",
    "\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import vertexai\n",
    "import vertexai.language_models as language_models\n",
    "import vertexai.preview.language_models as language_models_preview\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import documentai\n",
    "from google.cloud.documentai_v1 import Document\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "\n",
    "from IPython.display import display, Markdown, Latex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_3Rfhx874F2J"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'mg-ce-demos'\n",
    "REGION = 'us-central1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vertex ai clients\n",
    "vertexai.init(project = PROJECT_ID, location = REGION)\n",
    "aiplatform.init(project = PROJECT_ID, location = REGION)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Na0_rVVLhOk",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Ideate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "textgen_model_32k = language_models_preview.TextGenerationModel.from_pretrained('text-bison-32k')\n",
    "textgen_model = language_models.TextGenerationModel.from_pretrained('text-bison@latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide some context\n",
    "pre_text = \"Pretend you're a marketing specialist, \"\n",
    "\n",
    "# Ask the LLM\n",
    "text = \"Generate a social media post for a new manufacturing robot product\"\n",
    "\n",
    "prompt_ideate = pre_text+text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Prompt:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretend you're a marketing specialist, Generate a social media post for a new manufacturing robot product\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Response:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " Introducing the new manufacturing robot product - the ultimate solution for increased productivity and efficiency in your production line. With its state-of-the-art technology and user-friendly interface, this robot is designed to revolutionise the manufacturing industry. Say goodbye to manual labour and hello to a new era of automated production. #ManufacturingRobot #Automation #Productivity #Efficiency #Manufacturing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown('## Prompt:'))\n",
    "print(prompt_ideate)\n",
    "display(Markdown('## Response:'))\n",
    "\n",
    "# Send prompt to LLM\n",
    "display(Markdown(str(textgen_model.predict(\n",
    "   (prompt_ideate),\n",
    "    max_output_tokens=1024,\n",
    "    temperature=0.4,\n",
    "    top_p=0.8,\n",
    "    top_k=40,\n",
    ").text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Extract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide some context\n",
    "pre_text_extract = \"\"\"Extract the technical specifications from the text below in a JSON format.\n",
    "\n",
    "Text: type is Mechanical Joint Pipe, pipe size is 3, pipe thickness from .25 to .4, outside diameter is 3.96, bell weight is 11, bolts gasket weight is 7\n",
    "JSON: {\n",
    "  \\\"product_type\\\":\\\"Mechanical Joint Pipe\\\",\n",
    "  \\\"size_in\\\":\\\"3\\\",\n",
    "  \\\"thickness_in\\\": [\\\".25\\\", \\\".4\\\"],\n",
    "  \\\"out_diameter_in\\\":\\\"3.96\\\",\n",
    "  \\\"bell_weight_lb\\\":\\\"11\\\",\n",
    "  \\\"bolts_gasket_weight_lb\\\":\\\"7\\\"\n",
    "}\n",
    "\n",
    "Text: type is Mechanical Joint Pipe, pipe size is 4, pipe thickness from .26 to .41, outside diameter is 4.80, bell weight is 16, bolts gasket weight is 10\n",
    "JSON: {\n",
    "  \\\"product_type\\\":\\\"Mechanical Joint Pipe\\\",\n",
    "  \\\"size_in\\\":\\\"4\\\",\n",
    "  \\\"thickness_in\\\": [\\\".26\\\", \\\".41\\\"],\n",
    "  \\\"out_diameter_in\\\":\\\"4.8\\\",\n",
    "  \\\"bell_weight_lb\\\":\\\"16\\\",\n",
    "  \\\"bolts_gasket_weight_lb\\\":\\\"10\\\"\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Ask the LLM\n",
    "text_extract = \"\"\"Text: type is Mechanical Joint Pipe, pipe size is 5, bolts gasket weight is 12, outside diameter is 5.7, pipe thickness from .28 to .45, bell weight is 18\n",
    "JSON:\n",
    "\"\"\"\n",
    "\n",
    "prompt_extract = pre_text_extract+text_extract\n",
    "#print(prompt_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " {\n",
       "  \"product_type\":\"Mechanical Joint Pipe\",\n",
       "  \"size_in\":\"5\",\n",
       "  \"thickness_in\": [\".28\", \".45\"],\n",
       "  \"out_diameter_in\":\"5.7\",\n",
       "  \"bell_weight_lb\":\"18\",\n",
       "  \"bolts_gasket_weight_lb\":\"12\"\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(str(textgen_model.predict(\n",
    "   (prompt_extract),\n",
    "    max_output_tokens=1024,\n",
    "    temperature=0.4,\n",
    "    top_p=0.8,\n",
    "    top_k=40,\n",
    ").text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Now we can stick it behind a UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor_bot(text):\n",
    "    pre_text = \"\"\"Extract the technical specifications from the text below in a JSON format.\n",
    "\n",
    "    Text: type is Mechanical Joint Pipe, pipe size is 3, pipe thickness from .25 to .4, outside diameter is 3.96, bell weight is 11, bolts gasket weight is 7\n",
    "    JSON: {\n",
    "      \\\"product_type\\\":\\\"Mechanical Joint Pipe\\\",\n",
    "      \\\"size_in\\\":\\\"3\\\",\n",
    "      \\\"thickness_in\\\": [\\\".25\\\", \\\".4\\\"],\n",
    "      \\\"out_diameter_in\\\":\\\"3.96\\\",\n",
    "      \\\"bell_weight_lb\\\":\\\"11\\\",\n",
    "      \\\"bolts_gasket_weight_lb\\\":\\\"7\\\"\n",
    "    }\n",
    "    \n",
    "    Text: type is Mechanical Joint Pipe, pipe size is 4, pipe thickness from .26 to .41, outside diameter is 4.80, bell weight is 16, bolts gasket weight is 10\n",
    "    JSON: {\n",
    "      \\\"product_type\\\":\\\"Mechanical Joint Pipe\\\",\n",
    "      \\\"size_in\\\":\\\"4\\\",\n",
    "      \\\"thickness_in\\\": [\\\".26\\\", \\\".41\\\"],\n",
    "      \\\"out_diameter_in\\\":\\\"4.8\\\",\n",
    "      \\\"bell_weight_lb\\\":\\\"16\\\",\n",
    "      \\\"bolts_gasket_weight_lb\\\":\\\"10\\\"\n",
    "    }\n",
    "\n",
    "    Text: type is Mechanical Joint Pipe, pipe size is 4, pipe thickness from .26 to .41, bell weight is 16, bolts gasket weight is 10\n",
    "    JSON: {\n",
    "      \\\"product_type\\\":\\\"Mechanical Joint Pipe\\\",\n",
    "      \\\"size_in\\\":\\\"4\\\",\n",
    "      \\\"thickness_in\\\": [\\\".26\\\", \\\".41\\\"],\n",
    "      \\\"out_diameter_in\\\":,\n",
    "      \\\"bell_weight_lb\\\":\\\"16\\\",\n",
    "      \\\"bolts_gasket_weight_lb\\\":\\\"10\\\"\n",
    "    }\n",
    "    \n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"{pre_text}\n",
    "    \n",
    "    Text: {text}\n",
    "    JSON:\n",
    "    \"\"\"\n",
    "    \n",
    "    result = textgen_model.predict(\n",
    "        prompt,\n",
    "        max_output_tokens=1024,\n",
    "        temperature=0.4,\n",
    "        top_p=0.8,\n",
    "        top_k=40,\n",
    "    ).text\n",
    "\n",
    "    result_json = json.loads(result)\n",
    "    \n",
    "    return result, result_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marketing_bot(text):\n",
    "    pre_text = \"Pretend you're a marketing specialist, \"\n",
    "    prompt = pre_text + text\n",
    "    result = textgen_model.predict(\n",
    "        prompt,\n",
    "        max_output_tokens=1024,\n",
    "        temperature=0.4,\n",
    "        top_p=0.8,\n",
    "        top_k=40,\n",
    "    )\n",
    "    \n",
    "    return prompt, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7874\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7874/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import json\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\n",
    "    \"\"\"\n",
    "    ## Pocket Engineer Extractor\n",
    "    \"\"\")\n",
    "    with gr.Row():\n",
    "        input_text = gr.Textbox(label=\"Input Text\", value=\"type is Mechanical Joint Pipe, pipe size is 5, bolts gasket weight is 12, outside diameter is 5.7, pipe thickness from .28 to .45, bell weight is 18\")\n",
    "        \n",
    "    with gr.Row():\n",
    "        generate = gr.Button(\"Generate Response\")\n",
    "        \n",
    "    with gr.Row():\n",
    "        label3 = gr.Textbox(label=\"Response generated by LLM\")\n",
    "\n",
    "    with gr.Row():\n",
    "        label4 = gr.Textbox(label=\"JSON output\")\n",
    "\n",
    "    generate.click(extractor_bot, input_text, [label3, label4])\n",
    "demo.launch(share=False, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
