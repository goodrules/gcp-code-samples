{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sxq-V_jV4gEk",
    "tags": []
   },
   "source": [
    "# Using the Vertex AI PaLM API to Generate and Ideate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sHoUOuxf5GOR",
    "tags": []
   },
   "source": [
    "# Core code\n",
    "Let's define some variables that will be used throughout this notebook.\n",
    "\n",
    "These are the GCP Project ID `project_id`, the Model name `model_name` which is any name you prefer, and finally the Dataset name `dataset_name`.\n",
    "The dataset needs to exist in the same Project as `project_id` and you'll need appropriate access to create and delete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fU3_zsLsZ89c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertex AI version: 1.41.0\n"
     ]
    }
   ],
   "source": [
    "from typing import Union\n",
    "import sys\n",
    "\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "import concurrent.futures\n",
    "import time\n",
    "import http.client\n",
    "import typing\n",
    "import urllib.request\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import vertexai\n",
    "import vertexai.language_models as language_models\n",
    "import vertexai.preview.language_models as language_models_preview\n",
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    FunctionDeclaration,\n",
    "    GenerativeModel,\n",
    "    Part,\n",
    "    Tool,\n",
    ")\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import documentai\n",
    "from google.cloud.documentai_v1 import Document\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "print(\"Vertex AI version: \" + str(aiplatform.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_3Rfhx874F2J"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'mg-ce-demos'\n",
    "REGION = 'us-central1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vertex ai clients\n",
    "vertexai.init(project = PROJECT_ID, location = REGION)\n",
    "aiplatform.init(project = PROJECT_ID, location = REGION)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_generate(prompt):\n",
    "    result = []\n",
    "    model = GenerativeModel(\"gemini-pro\")\n",
    "    responses = model.generate_content(\n",
    "        [prompt],\n",
    "        generation_config={\n",
    "            \"max_output_tokens\": 2048,\n",
    "            \"temperature\": 0.5,\n",
    "            \"top_p\": 1\n",
    "        },\n",
    "        stream=True,\n",
    "    )\n",
    "  \n",
    "    for response in responses:\n",
    "        result.append(response.candidates[0].content.parts[0].text)\n",
    "\n",
    "    result = ''.join(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Write a short story about a dog playing in the snow\"\"\"\n",
    "\n",
    "result_txt = gemini_generate(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the heart of a quaint little town, where snowflakes danced and painted the world in shades of white, lived a dog named Buddy. Buddy, with his wagging tail and boundless energy, found endless joy in the arrival of winter.\n",
      "\n",
      "One crisp morning, as the sun peeked through the clouds, Buddy's excitement reached new heights. He watched from the window as the snow glistened and sparkled, calling him to an adventure he couldn't resist.\n",
      "\n",
      "With a bark of delight, Buddy dashed out the door, his paws sinking into the soft, powdery snow. He reveled in the sensation, feeling the cold beneath his fur and the crunch beneath his feet.\n",
      "\n",
      "As he explored the snow-covered streets, Buddy discovered a winter wonderland that was all his own. He chased snowflakes as they twirled and spun, creating a flurry of white magic around him.\n",
      "\n",
      "He rolled and tumbled in the snow, leaving behind trails of doggy joy. His laughter echoed through the quiet streets as he slid down snowy slopes and jumped over snow-covered obstacles.\n",
      "\n",
      "Buddy's adventure took him to the nearby park, where he found a group of children building a snowman. With his friendly nature, he quickly became part of their winter fun.\n",
      "\n",
      "The children squealed with laughter as Buddy helped them roll the giant snowball, barking and wagging his tail in encouragement. Together, they created a magnificent snowman that stood tall and proud, a symbol of their winter camaraderie.\n",
      "\n",
      "As the sun began to set, casting a warm glow over the snowy landscape, Buddy knew it was time to head home. With a satisfied sigh, he shook off the snow from his fur and trotted back home, his heart filled with the warmth of the winter day's adventures.\n",
      "\n",
      "That night, as Buddy curled up in his cozy bed, he dreamed of the magical winter wonderland he had explored. The memories of his snowy escapade would warm his heart and bring a smile to his face until the next snow-filled day arrived.\n"
     ]
    }
   ],
   "source": [
    "print(result_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### multimodal - image and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create helper function\n",
    "def load_image_from_url(image_url: str) -> Image:\n",
    "    with urllib.request.urlopen(image_url) as response:\n",
    "        response = typing.cast(http.client.HTTPResponse, response)\n",
    "        image_bytes = response.read()\n",
    "    return Image.from_bytes(image_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_generate_multi_w_image(prompt_list):\n",
    "    result = []\n",
    "    model = GenerativeModel(\"gemini-pro-vision\")\n",
    "    responses = model.generate_content(\n",
    "        prompt_list, # prompt_list format is [image, prompt, image, prompt, ...]\n",
    "        generation_config={\n",
    "            \"max_output_tokens\": 2048,\n",
    "            \"temperature\": 0.4,\n",
    "            \"top_p\": 1,\n",
    "            \"top_k\": 32\n",
    "        },\n",
    "        stream=True,\n",
    "    )\n",
    "  \n",
    "    for response in responses:\n",
    "        result.append(response.candidates[0].content.parts[0].text)\n",
    "\n",
    "    result = ''.join(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images from Cloud Storage URI\n",
    "landmark1 = load_image_from_url(\"https://storage.googleapis.com/cloud-samples-data/vertex-ai/llm/prompts/landmark1.png\")\n",
    "landmark2 = load_image_from_url(\"https://storage.googleapis.com/cloud-samples-data/vertex-ai/llm/prompts/landmark2.png\")\n",
    "landmark3 = load_image_from_url(\"https://storage.googleapis.com/cloud-samples-data/vertex-ai/llm/prompts/landmark3.png\")\n",
    "\n",
    "# for local images\n",
    "## source_image = Image.load_from_file(location='./gen-img1.png')\n",
    "\n",
    "# create multimodal prompt\n",
    "prompt_data_img = [landmark1, \"city: Rome, Landmark: the Colosseum\", \n",
    "               landmark2, \"city: Beijing, Landmark: Forbidden City\",\n",
    "               landmark3, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_img = gemini_generate_multi_w_image(prompt_data_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " city: Rio de Janeiro, Landmark: Christ the Redeemer\n"
     ]
    }
   ],
   "source": [
    "print(result_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### multimodal - video and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_generate_multi_w_vid(prompt_list):\n",
    "    model = GenerativeModel(\"gemini-pro-vision\")\n",
    "    # Generate text\n",
    "    response = model.generate_content(prompt_list) #prompt_list format is [prompt, video_data]\n",
    "    \n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_data = Part.from_uri(\"gs://cloud-samples-data/video/animals.mp4\", mime_type=\"video/mp4\")\n",
    "\n",
    "prompt_data_vid = [\"\"\"What is in the video?\"\"\", video_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_vid = gemini_generate_multi_w_vid(prompt_data_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The video is an advertisement for the movie Zootopia. It features a tiger, a sloth, and an otter. The tiger is shown stalking the sloth, but the sloth is saved by the otter. The video is set in a rainforest, and the animals are all shown in their natural habitats. The video is narrated by a human, who provides information about the animals and the rainforest.\n"
     ]
    }
   ],
   "source": [
    "print(result_vid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gem_model = GenerativeModel(\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I do not have access to real-time information and cannot provide the current exchange rate. For the most up-to-date information, please refer to a reliable source such as a currency converter or a financial news website.\n"
     ]
    }
   ],
   "source": [
    "response = gem_model.generate_content(\n",
    "    \"What's the exchange rate for euros to dollars today?\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "{\n",
      "  \"from_currency\": \"euros\",\n",
      "  \"to_currency\": \"US dollars\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"What's the exchange rate from euros to US dollars today?\"\n",
    "\n",
    "response = gem_model.generate_content(\"\"\"\n",
    "Your task is to extract parameters from the user's input and return it as a\n",
    "structured JSON payload. The user will ask about the exchange rate and which\n",
    "currency they are converting from and converting to.\n",
    "\n",
    "User input: {user_prompt}\n",
    "\n",
    "Please extract the currencies as parameters and put them in a JSON object.\n",
    "\"\"\".format(user_prompt=user_prompt))\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"amount\":1.0,\"base\":\"EUR\",\"date\":\"2024-02-29\",\"rates\":{\"AUD\":1.6684,\"BGN\":1.9558,\"BRL\":5.4054,\"CAD\":1.4719,\"CHF\":0.9534,\"CNY\":7.7888,\"CZK\":25.363,\"DKK\":7.454,\"GBP\":0.85655,\"HKD\":8.4735,\"HUF\":393.48,\"IDR\":17038,\"ILS\":3.8736,\"INR\":89.75,\"ISK\":149.3,\"JPY\":162.53,\"KRW\":1447.43,\"MXN\":18.4969,\"MYR\":5.1375,\"NOK\":11.492,\"NZD\":1.7807,\"PHP\":60.858,\"PLN\":4.3208,\"RON\":4.9706,\"SEK\":11.215,\"SGD\":1.457,\"THB\":38.909,\"TRY\":33.807,\"USD\":1.0826,\"ZAR\":20.901}}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "url = \"https://api.frankfurter.app/latest\"\n",
    "response = requests.get(url)\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_exchange_rate_func = FunctionDeclaration(\n",
    "    name=\"get_exchange_rate\",\n",
    "    description=\"Get the exchange rate for currencies between countries\",\n",
    "    parameters={\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"currency_date\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"A date that must always be in YYYY-MM-DD format or the value 'latest' if a time period is not specified\"\n",
    "        },\n",
    "        \"currency_from\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The currency to convert from in ISO 4217 format\"\n",
    "        },\n",
    "        \"currency_to\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The currency to convert to in ISO 4217 format\"\n",
    "        }\n",
    "    },\n",
    "         \"required\": [\n",
    "            \"currency_from\",\n",
    "            \"currency_date\",\n",
    "      ]\n",
    "  },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_rate_tool = Tool(\n",
    "    function_declarations=[get_exchange_rate_func],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"What is the exchange rate from Australian dollars to Swedish krona?\n",
    "How much is 500 Australian dollars worth in Swedish krona?\"\"\"\n",
    "\n",
    "response = gem_model.generate_content(\n",
    "    prompt,\n",
    "    tools=[exchange_rate_tool],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role: \"model\"\n",
      "parts {\n",
      "  function_call {\n",
      "    name: \"get_exchange_rate\"\n",
      "    args {\n",
      "      fields {\n",
      "        key: \"currency_to\"\n",
      "        value {\n",
      "          string_value: \"SEK\"\n",
      "        }\n",
      "      }\n",
      "      fields {\n",
      "        key: \"currency_from\"\n",
      "        value {\n",
      "          string_value: \"AUD\"\n",
      "        }\n",
      "      }\n",
      "      fields {\n",
      "        key: \"currency_date\"\n",
      "        value {\n",
      "          string_value: \"latest\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.candidates[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'from': 'AUD', 'date': 'latest', 'to': 'SEK'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {}\n",
    "for key, value in response.candidates[0].content.parts[0].function_call.args.items():\n",
    "    params[key[9:]] = value\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"amount\":1.0,\"base\":\"AUD\",\"date\":\"2024-02-29\",\"rates\":{\"SEK\":6.722}}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "url = f\"https://api.frankfurter.app/{params['date']}\"\n",
    "api_response = requests.get(url, params=params)\n",
    "api_response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The exchange rate from Australian dollars to Swedish krona on 2024-02-29 is 1 AUD = 6.722 SEK.\\nTherefore, 500 Australian dollars is worth 6.722 * 500 = 3361 Swedish krona.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = gem_model.generate_content(\n",
    "    [\n",
    "    Content(role=\"user\", parts=[\n",
    "        Part.from_text(prompt + \"\"\"Give your answer in steps with lots of detail\n",
    "            and context, including the exchange rate and date.\"\"\"),\n",
    "    ]),\n",
    "    Content(role=\"function\", parts=[\n",
    "        Part.from_dict({\n",
    "            \"function_call\": {\n",
    "                \"name\": \"get_exchange_rate\",\n",
    "            }\n",
    "        })\n",
    "    ]),\n",
    "    Content(role=\"function\", parts=[\n",
    "        Part.from_function_response(\n",
    "            name=\"get_exchange_rate\",\n",
    "            response={\n",
    "                \"content\": api_response.text,\n",
    "            }\n",
    "        )\n",
    "    ]),\n",
    "    ],\n",
    "    tools=[exchange_rate_tool],\n",
    ")\n",
    "\n",
    "\n",
    "response.candidates[0].content.parts[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Na0_rVVLhOk",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Ideate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "textgen_model_32k = language_models_preview.TextGenerationModel.from_pretrained('text-bison-32k')\n",
    "textgen_model = language_models.TextGenerationModel.from_pretrained('text-bison@latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide some context\n",
    "pre_text = \"Pretend you're a marketing specialist, \"\n",
    "\n",
    "# Ask the LLM\n",
    "text = \"Generate a social media post for a new manufacturing robot product\"\n",
    "\n",
    "prompt_ideate = pre_text+text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Prompt:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretend you're a marketing specialist, Generate a social media post for a new manufacturing robot product\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Response:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " Introducing the new manufacturing robot product - the ultimate solution for increased productivity and efficiency in your production line. With its state-of-the-art technology and user-friendly interface, this robot is designed to revolutionise the manufacturing industry. Say goodbye to manual labour and hello to a new era of automated production. #ManufacturingRobot #Automation #Productivity #Efficiency #Manufacturing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown('## Prompt:'))\n",
    "print(prompt_ideate)\n",
    "display(Markdown('## Response:'))\n",
    "\n",
    "# Send prompt to LLM\n",
    "display(Markdown(str(textgen_model.predict(\n",
    "   (prompt_ideate),\n",
    "    max_output_tokens=1024,\n",
    "    temperature=0.4,\n",
    "    top_p=0.8,\n",
    "    top_k=40,\n",
    ").text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Extract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide some context\n",
    "pre_text_extract = \"\"\"Extract the technical specifications from the text below in a JSON format.\n",
    "\n",
    "Text: type is Mechanical Joint Pipe, pipe size is 3, pipe thickness from .25 to .4, outside diameter is 3.96, bell weight is 11, bolts gasket weight is 7\n",
    "JSON: {\n",
    "  \\\"product_type\\\":\\\"Mechanical Joint Pipe\\\",\n",
    "  \\\"size_in\\\":\\\"3\\\",\n",
    "  \\\"thickness_in\\\": [\\\".25\\\", \\\".4\\\"],\n",
    "  \\\"out_diameter_in\\\":\\\"3.96\\\",\n",
    "  \\\"bell_weight_lb\\\":\\\"11\\\",\n",
    "  \\\"bolts_gasket_weight_lb\\\":\\\"7\\\"\n",
    "}\n",
    "\n",
    "Text: type is Mechanical Joint Pipe, pipe size is 4, pipe thickness from .26 to .41, outside diameter is 4.80, bell weight is 16, bolts gasket weight is 10\n",
    "JSON: {\n",
    "  \\\"product_type\\\":\\\"Mechanical Joint Pipe\\\",\n",
    "  \\\"size_in\\\":\\\"4\\\",\n",
    "  \\\"thickness_in\\\": [\\\".26\\\", \\\".41\\\"],\n",
    "  \\\"out_diameter_in\\\":\\\"4.8\\\",\n",
    "  \\\"bell_weight_lb\\\":\\\"16\\\",\n",
    "  \\\"bolts_gasket_weight_lb\\\":\\\"10\\\"\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Ask the LLM\n",
    "text_extract = \"\"\"Text: type is Mechanical Joint Pipe, pipe size is 5, bolts gasket weight is 12, outside diameter is 5.7, pipe thickness from .28 to .45, bell weight is 18\n",
    "JSON:\n",
    "\"\"\"\n",
    "\n",
    "prompt_extract = pre_text_extract+text_extract\n",
    "#print(prompt_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " {\n",
       "  \"product_type\":\"Mechanical Joint Pipe\",\n",
       "  \"size_in\":\"5\",\n",
       "  \"thickness_in\": [\".28\", \".45\"],\n",
       "  \"out_diameter_in\":\"5.7\",\n",
       "  \"bell_weight_lb\":\"18\",\n",
       "  \"bolts_gasket_weight_lb\":\"12\"\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(str(textgen_model.predict(\n",
    "   (prompt_extract),\n",
    "    max_output_tokens=1024,\n",
    "    temperature=0.4,\n",
    "    top_p=0.8,\n",
    "    top_k=40,\n",
    ").text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Now we can stick it behind a UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor_bot(text):\n",
    "    pre_text = \"\"\"Extract the technical specifications from the text below in a JSON format.\n",
    "\n",
    "    Text: type is Mechanical Joint Pipe, pipe size is 3, pipe thickness from .25 to .4, outside diameter is 3.96, bell weight is 11, bolts gasket weight is 7\n",
    "    JSON: {\n",
    "      \\\"product_type\\\":\\\"Mechanical Joint Pipe\\\",\n",
    "      \\\"size_in\\\":\\\"3\\\",\n",
    "      \\\"thickness_in\\\": [\\\".25\\\", \\\".4\\\"],\n",
    "      \\\"out_diameter_in\\\":\\\"3.96\\\",\n",
    "      \\\"bell_weight_lb\\\":\\\"11\\\",\n",
    "      \\\"bolts_gasket_weight_lb\\\":\\\"7\\\"\n",
    "    }\n",
    "    \n",
    "    Text: type is Mechanical Joint Pipe, pipe size is 4, pipe thickness from .26 to .41, outside diameter is 4.80, bell weight is 16, bolts gasket weight is 10\n",
    "    JSON: {\n",
    "      \\\"product_type\\\":\\\"Mechanical Joint Pipe\\\",\n",
    "      \\\"size_in\\\":\\\"4\\\",\n",
    "      \\\"thickness_in\\\": [\\\".26\\\", \\\".41\\\"],\n",
    "      \\\"out_diameter_in\\\":\\\"4.8\\\",\n",
    "      \\\"bell_weight_lb\\\":\\\"16\\\",\n",
    "      \\\"bolts_gasket_weight_lb\\\":\\\"10\\\"\n",
    "    }\n",
    "\n",
    "    Text: type is Mechanical Joint Pipe, pipe size is 4, pipe thickness from .26 to .41, bell weight is 16, bolts gasket weight is 10\n",
    "    JSON: {\n",
    "      \\\"product_type\\\":\\\"Mechanical Joint Pipe\\\",\n",
    "      \\\"size_in\\\":\\\"4\\\",\n",
    "      \\\"thickness_in\\\": [\\\".26\\\", \\\".41\\\"],\n",
    "      \\\"out_diameter_in\\\":,\n",
    "      \\\"bell_weight_lb\\\":\\\"16\\\",\n",
    "      \\\"bolts_gasket_weight_lb\\\":\\\"10\\\"\n",
    "    }\n",
    "    \n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"{pre_text}\n",
    "    \n",
    "    Text: {text}\n",
    "    JSON:\n",
    "    \"\"\"\n",
    "    \n",
    "    result = textgen_model.predict(\n",
    "        prompt,\n",
    "        max_output_tokens=1024,\n",
    "        temperature=0.4,\n",
    "        top_p=0.8,\n",
    "        top_k=40,\n",
    "    ).text\n",
    "\n",
    "    result_json = json.loads(result)\n",
    "    \n",
    "    return result, result_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marketing_bot(text):\n",
    "    pre_text = \"Pretend you're a marketing specialist, \"\n",
    "    prompt = pre_text + text\n",
    "    result = textgen_model.predict(\n",
    "        prompt,\n",
    "        max_output_tokens=1024,\n",
    "        temperature=0.4,\n",
    "        top_p=0.8,\n",
    "        top_k=40,\n",
    "    )\n",
    "    \n",
    "    return prompt, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7874\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7874/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import json\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\n",
    "    \"\"\"\n",
    "    ## Pocket Engineer Extractor\n",
    "    \"\"\")\n",
    "    with gr.Row():\n",
    "        input_text = gr.Textbox(label=\"Input Text\", value=\"type is Mechanical Joint Pipe, pipe size is 5, bolts gasket weight is 12, outside diameter is 5.7, pipe thickness from .28 to .45, bell weight is 18\")\n",
    "        \n",
    "    with gr.Row():\n",
    "        generate = gr.Button(\"Generate Response\")\n",
    "        \n",
    "    with gr.Row():\n",
    "        label3 = gr.Textbox(label=\"Response generated by LLM\")\n",
    "\n",
    "    with gr.Row():\n",
    "        label4 = gr.Textbox(label=\"JSON output\")\n",
    "\n",
    "    generate.click(extractor_bot, input_text, [label3, label4])\n",
    "demo.launch(share=False, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
