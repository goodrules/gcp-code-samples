{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7545cfba-222c-402b-8a25-d72a4f54d6ae",
   "metadata": {},
   "source": [
    "# Transcribe Audio and Summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39335246-8e26-411a-bcd3-580a05b391f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a525434-5af1-4aa3-a919-e17563637df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -qlalchemy (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -dit-py-plugins (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-aiplatform (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting google-cloud-speech\n",
      "  Downloading google_cloud_speech-2.20.0-py2.py3-none-any.whl (273 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.6/273.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-speech) (1.34.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-speech) (1.22.2)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.7/site-packages (from google-cloud-speech) (3.19.6)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (1.56.4)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (2.17.3)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (2.28.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (1.48.1)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (1.48.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (0.2.7)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (4.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (2022.12.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (0.4.8)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -qlalchemy (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -dit-py-plugins (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-aiplatform (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: google-cloud-speech\n",
      "Successfully installed google-cloud-speech-2.20.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -qlalchemy (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -dit-py-plugins (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-aiplatform (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: vertexai in /opt/conda/lib/python3.7/site-packages (0.0.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -qlalchemy (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -dit-py-plugins (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-aiplatform (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -qlalchemy (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -dit-py-plugins (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-aiplatform (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -qlalchemy (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -dit-py-plugins (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -oogle-cloud-aiplatform (/opt/conda/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-cloud-speech\n",
    "!pip install vertexai\n",
    "!pip install google-cloud-aiplatform>=1.25 \"shapely<2.0.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9556d7c8-e01e-49f4-8ef8-28ad4af6af45",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "033bbdee-f76c-48c6-990d-02e6d168f575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable Vertex AI FOr This Project\n",
    "!gcloud services enable aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ffbe27c-6d21-4a31-8c83-16b04687db5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mg-ce-demos'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a65246a1-f787-4bfd-a052-f066d40b2e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "LOCATION = 'us'\n",
    "EXPERIMENT = 'chirp-stt'\n",
    "SERIES = 'applied-genai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16cd468e-58ba-4876-92c4-ce224cb7c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "import shapely\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import vertexai\n",
    "from vertexai.preview.language_models import TextGenerationModel, TextEmbeddingModel, ChatModel\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech_v2 import SpeechClient\n",
    "from google.cloud.speech_v2.types import cloud_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b41da093-2964-49c6-bba7-1ffa3c91ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexai.init(project = PROJECT_ID, location = REGION)\n",
    "aiplatform.init(project = PROJECT_ID, location = REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94ce87eb-9a50-415a-8c39-6713b3b12977",
   "metadata": {},
   "outputs": [],
   "source": [
    "stt = speech.SpeechClient()\n",
    "gcs = storage.Client(project = PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e51122b-5f9e-4328-a2fa-c8bf894101c9",
   "metadata": {},
   "source": [
    "## Get URI's from GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2414ae69-592b-4226-8b1e-14d6523843bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_audio_uri = \"speech/brooklyn_bridge.flac\"\n",
    "example_audio_uri2 = \"speech/sample-podcasts/GCPEpisode328-DatabaseMigrationService-2min sample.flac\"\n",
    "\n",
    "gcs_bucket = 'cloud-samples-data'\n",
    "bucket = gcs.bucket(gcs_bucket)\n",
    "blob = bucket.blob(example_audio_uri2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3c837eb-59c6-40e0-a936-29c9e656ffc8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speech/\n",
      "speech/Google_Gnome.wav\n",
      "speech/VER_video_series/\n",
      "speech/VER_video_series/Anu1.flac\n",
      "speech/VER_video_series/Anu1.m4a\n",
      "speech/VER_video_series/Anu1.wav\n",
      "speech/VER_video_series/Anu2.wav\n",
      "speech/VER_video_series/estella.wav\n",
      "speech/VER_video_series/restaurants.wav\n",
      "speech/VER_video_series/restaurants2.wav\n",
      "speech/VER_video_series/restaurants3.wav\n",
      "speech/VER_video_series/restaurants4.wav\n",
      "speech/VER_video_series/restaurants5.wav\n",
      "speech/VER_video_series/restaurants6.wav\n",
      "speech/VER_video_series/restaurants7.wav\n",
      "speech/VER_video_series/restaurants8.wav\n",
      "speech/audio.flac\n",
      "speech/audio.raw\n",
      "speech/audio.txt\n",
      "speech/brooklyn_bridge.flac\n",
      "speech/brooklyn_bridge.mp3\n",
      "speech/brooklyn_bridge.raw\n",
      "speech/brooklyn_bridge.wav\n",
      "speech/clip.flac\n",
      "speech/clip.txt\n",
      "speech/commercial_mono.wav\n",
      "speech/commercial_stereo.wav\n",
      "speech/corbeau_renard.flac\n",
      "speech/en-US.wav\n",
      "speech/hello.flac\n",
      "speech/hello.raw\n",
      "speech/hello.wav\n",
      "speech/listen/Alice_51_sample_mix.aif\n",
      "speech/listen/Alice_BL.flac\n",
      "speech/listen/Alice_BR.flac\n",
      "speech/listen/Alice_FC.flac\n",
      "speech/listen/Alice_FL.flac\n",
      "speech/listen/Alice_FR.flac\n",
      "speech/listen/Alice_LFE.flac\n",
      "speech/listen/Alice_mono_downmix.flac\n",
      "speech/listen/HumptyDumpty4416.flac\n",
      "speech/listen/HumptyDumptySample0808.flac\n",
      "speech/listen/HumptyDumptySample1116.flac\n",
      "speech/listen/HumptyDumptySample1616.flac\n",
      "speech/listen/HumptyDumptySample2208.flac\n",
      "speech/listen/HumptyDumptySample2216.flac\n",
      "speech/listen/HumptyDumptySample4408.flac\n",
      "speech/listen/HumptyDumptySample4408to16.flac\n",
      "speech/listen/HumptyDumptySample4416.flac\n",
      "speech/listen/HumptyDumptySampleStereo.flac\n",
      "speech/listen/HumptyDumptySample_FL.flac\n",
      "speech/listen/HumptyDumptySample_FR.flac\n",
      "speech/listen/HumptyDumptyUpSample4416.flac\n",
      "speech/listen/Speech_11k8b.flac\n",
      "speech/listen/Speech_16k16b.flac\n",
      "speech/listen/Speech_16k8b.flac\n",
      "speech/listen/Speech_441k16b.flac\n",
      "speech/listen/Speech_441k8b.flac\n",
      "speech/listen/Speech_48k16bNonFloatingPoint.wav\n",
      "speech/listen/Speech_48kFloat.wav\n",
      "speech/listen/sample_51_mix_movie.mp4\n",
      "speech/listen/sample_BL.flac\n",
      "speech/listen/sample_BR.flac\n",
      "speech/listen/sample_FC.flac\n",
      "speech/listen/sample_FL.flac\n",
      "speech/listen/sample_FR.flac\n",
      "speech/listen/sample_LFE.flac\n",
      "speech/medical_conversation_2.wav\n",
      "speech/multi.flac\n",
      "speech/multi.wav\n",
      "speech/multi_es.flac\n",
      "speech/multi_es.wav\n",
      "speech/project_archive/sample_stt_api_project_files.zip\n",
      "speech/project_files/Alice_51_sample_mix.aif\n",
      "speech/project_files/Alice_mono_downmix.flac\n",
      "speech/project_files/HumptyDumpty4416.flac\n",
      "speech/project_files/HumptyDumptySample0808.flac\n",
      "speech/project_files/HumptyDumptySample1116.flac\n",
      "speech/project_files/HumptyDumptySample1616.flac\n",
      "speech/project_files/HumptyDumptySample2208.flac\n",
      "speech/project_files/HumptyDumptySample2216.flac\n",
      "speech/project_files/HumptyDumptySample4408.flac\n",
      "speech/project_files/HumptyDumptySample4408to16.flac\n",
      "speech/project_files/HumptyDumptySample4416.flac\n",
      "speech/project_files/HumptyDumptySampleStereo.flac\n",
      "speech/project_files/HumptyDumptyUpSample4416.flac\n",
      "speech/project_files/Speech_11k8b.flac\n",
      "speech/project_files/Speech_16k16b.flac\n",
      "speech/project_files/Speech_16k8b.flac\n",
      "speech/project_files/Speech_441k16b.flac\n",
      "speech/project_files/Speech_441k8b.flac\n",
      "speech/project_files/Speech_48k16bNonFloatingPoint.wav\n",
      "speech/project_files/Speech_48kFloat.wav\n",
      "speech/project_files/sample_51_mix_movie.mp4\n",
      "speech/sample-podcasts/\n",
      "speech/sample-podcasts/GCPEpisode328-DatabaseMigrationService-2min sample.flac\n",
      "speech/time.mp3\n"
     ]
    }
   ],
   "source": [
    "gcs_bucket = 'cloud-samples-data'\n",
    "bucket = gcs.bucket(gcs_bucket)\n",
    "# Get the list of blobs\n",
    "blobs = bucket.list_blobs()\n",
    "\n",
    "# Loop through the blobs\n",
    "pdf_data = []\n",
    "for blob in blobs:\n",
    "    if blob.name.startswith('speech/'):\n",
    "        print(blob.name)\n",
    "        #pdf_data.append([blob.name, blob.content_type, blob.download_as_bytes()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be04234f-2dcc-4ff6-98aa-c344dc2e6641",
   "metadata": {},
   "source": [
    "## Setup recognizer and download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83e14183-3fdc-4adf-bde0-f31afe2eefaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recognizer = 'chirp-recognizer'\n",
    "#stt_model = 'chirp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c431e73e-cd8f-4fef-8021-a6bed5feba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_bytes = blob.download_as_bytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7c0ba35-8254-4a7a-96fe-678902765d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(audio_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d630a6d6-daf0-4956-af1b-97b185e8d91e",
   "metadata": {},
   "source": [
    "## Quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2eab0035-052d-4dc0-8bc2-adb64b8abdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stt_demo(gcs_uri) -> speech.RecognizeResponse:\n",
    "    # Instantiates a client\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    # The name of the audio file to transcribe\n",
    "    gcs_uri = gcs_uri\n",
    "\n",
    "    audio = speech.RecognitionAudio(uri=gcs_uri)\n",
    "    \n",
    "    diarization_config = speech.SpeakerDiarizationConfig(\n",
    "        enable_speaker_diarization=True,\n",
    "        min_speaker_count=2,\n",
    "        max_speaker_count=10,\n",
    "    )\n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.FLAC,\n",
    "        #sample_rate_hertz=16000,\n",
    "        audio_channel_count=2,\n",
    "        language_code=\"en-US\",\n",
    "        enable_word_confidence=True,\n",
    "        #enable_word_time_offsets=True,\n",
    "        model=\"default\",\n",
    "        #enable_speaker_diarization=True,\n",
    "        diarization_config=diarization_config,\n",
    "    )\n",
    "\n",
    "    # Detects speech in the audio file\n",
    "    operation = stt.long_running_recognize(config=config, audio=audio)\n",
    "\n",
    "    print(\"Waiting for operation to complete...\")\n",
    "    response = operation.result(timeout=90)\n",
    "\n",
    "    #for result in response.results:\n",
    "    #    print(f\"Transcript: {result.alternatives[0].transcript}\")\n",
    "        \n",
    "    # The transcript within each result is separate and sequential per result.\n",
    "    # However, the words list within an alternative includes all the words\n",
    "    # from all the results thus far. Thus, to get all the words with speaker\n",
    "    # tags, you only have to take the words list from the last result:\n",
    "    result = response.results[-1]\n",
    "\n",
    "    words_info = result.alternatives[0].words\n",
    "\n",
    "    # Printing out the output:\n",
    "    for word_info in words_info:\n",
    "        print(f\"word: '{word_info.word}', speaker_tag: {word_info.speaker_tag}\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68fa0c4f-e0d7-4ef4-8e55-9f17398cc044",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown field for RecognitionConfig: enable_speaker_diarization",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstt_demo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgcs_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgs://cloud-samples-data/speech/sample-podcasts/GCPEpisode328-DatabaseMigrationService-2min sample.flac\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[41], line 16\u001b[0m, in \u001b[0;36mstt_demo\u001b[0;34m(gcs_uri)\u001b[0m\n\u001b[1;32m      8\u001b[0m audio \u001b[38;5;241m=\u001b[39m speech\u001b[38;5;241m.\u001b[39mRecognitionAudio(uri\u001b[38;5;241m=\u001b[39mgcs_uri)\n\u001b[1;32m     10\u001b[0m diarization_config \u001b[38;5;241m=\u001b[39m speech\u001b[38;5;241m.\u001b[39mSpeakerDiarizationConfig(\n\u001b[1;32m     11\u001b[0m     enable_speaker_diarization\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m     min_speaker_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     13\u001b[0m     max_speaker_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mspeech\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRecognitionConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeech\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRecognitionConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAudioEncoding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFLAC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#sample_rate_hertz=16000,\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43maudio_channel_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlanguage_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men-US\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_word_confidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#enable_word_time_offsets=True,\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefault\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_speaker_diarization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiarization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiarization_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Detects speech in the audio file\u001b[39;00m\n\u001b[1;32m     29\u001b[0m operation \u001b[38;5;241m=\u001b[39m stt\u001b[38;5;241m.\u001b[39mlong_running_recognize(config\u001b[38;5;241m=\u001b[39mconfig, audio\u001b[38;5;241m=\u001b[39maudio)\n",
      "File \u001b[0;32m~/Documents/developer/venv/lib/python3.9/site-packages/proto/message.py:565\u001b[0m, in \u001b[0;36mMessage.__init__\u001b[0;34m(self, mapping, ignore_unknown_fields, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ignore_unknown_fields:\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown field for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, key)\n\u001b[1;32m    567\u001b[0m     )\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    570\u001b[0m     pb_value \u001b[38;5;241m=\u001b[39m marshal\u001b[38;5;241m.\u001b[39mto_proto(pb_type, value)\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown field for RecognitionConfig: enable_speaker_diarization"
     ]
    }
   ],
   "source": [
    "stt_demo(gcs_uri=\"gs://cloud-samples-data/speech/sample-podcasts/GCPEpisode328-DatabaseMigrationService-2min sample.flac\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b93dd00-fea8-4f48-9f4f-77e7b7c1ba2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run transcriber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d1e7dc4d-59ce-47ec-98b8-e169c3a23a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_speech(audio_bytes):\n",
    "  audio = speech.RecognitionAudio(content=audio_bytes)\n",
    "\n",
    "  config = speech.RecognitionConfig(\n",
    "    encoding=speech.RecognitionConfig.AudioEncoding.FLAC,\n",
    "    language_code=\"en-US\",\n",
    "    model=\"default\",\n",
    "    audio_channel_count=1,\n",
    "    enable_word_confidence=True,\n",
    "    enable_word_time_offsets=True,\n",
    "  )\n",
    "\n",
    "  # Detects speech in the audio file\n",
    "  operation = stt.long_running_recognize(config=config, audio=audio)\n",
    "\n",
    "  print(\"Waiting for operation to complete...\")\n",
    "  response = operation.result(timeout=90)\n",
    "    \n",
    "  return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4789587c-0816-4221-ac41-8a225d18dbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for operation to complete...\n",
      "CPU times: user 5.26 ms, sys: 3.15 ms, total: 8.41 ms\n",
      "Wall time: 1.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "text = transcribe_speech(audio_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "69356055-6d83-49c3-9584-90866260176a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: how old is the Brooklyn Bridge\n"
     ]
    }
   ],
   "source": [
    "for result in text.results:\n",
    "    print(\"Transcript: {}\".format(result.alternatives[0].transcript))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8344cb96-d2f5-4062-90c7-07ff2ac098f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "MP3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m config \u001b[38;5;241m=\u001b[39m speech\u001b[38;5;241m.\u001b[39mRecognitionConfig(\n\u001b[0;32m----> 2\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m \u001b[43mspeech\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRecognitionConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAudioEncoding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMP3\u001b[49m,\n\u001b[1;32m      3\u001b[0m     sample_rate_hertz \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16000\u001b[39m,\n\u001b[1;32m      4\u001b[0m     language_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men-US\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m text \u001b[38;5;241m=\u001b[39m stt\u001b[38;5;241m.\u001b[39mrecognize(\n\u001b[1;32m      8\u001b[0m     config \u001b[38;5;241m=\u001b[39m config,\n\u001b[1;32m      9\u001b[0m     audio \u001b[38;5;241m=\u001b[39m stt\u001b[38;5;241m.\u001b[39mRecognitionAudio(content \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39maudio_bytes)\n\u001b[1;32m     10\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/enum.py:429\u001b[0m, in \u001b[0;36mEnumMeta.__getattr__\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_member_map_[name]\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 429\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(name) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: MP3"
     ]
    }
   ],
   "source": [
    "config = speech.RecognitionConfig(\n",
    "    encoding = speech.RecognitionConfig.AudioEncoding.MP3,\n",
    "    sample_rate_hertz = 16000,\n",
    "    language_code = \"en-US\"\n",
    ")\n",
    "\n",
    "text = stt.recognize(\n",
    "    config = config,\n",
    "    audio = stt.RecognitionAudio(content = response.audio_bytes)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c5c9e2-3331-4124-a335-6740f6a143db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
